# SISTEMA COMPLETO - Clone Digital do Endrigo
## Documenta√ß√£o T√©cnica Integral - Todas as Funcionalidades

---

## üìã √çNDICE

1. [Vis√£o Geral do Sistema](#vis√£o-geral-do-sistema)
2. [Arquitetura Completa](#arquitetura-completa)
3. [Todos os C√≥digos](#todos-os-c√≥digos)
4. [Banco de Dados](#banco-de-dados)
5. [Servi√ßos Externos](#servi√ßos-externos)
6. [Frontend e Interface](#frontend-e-interface)
7. [Sistema de Webhooks](#sistema-de-webhooks)
8. [Configura√ß√£o Completa](#configura√ß√£o-completa)
9. [Problemas e Solu√ß√µes](#problemas-e-solu√ß√µes)
10. [Guias de Deploy](#guias-de-deploy)

---

## üéØ VIS√ÉO GERAL DO SISTEMA

### Sistema Completo Implementado
- **Flask Web Framework** - Servidor principal com m√∫ltiplos webhooks
- **PostgreSQL Database** - Neon Cloud para armazenamento de conversas
- **OpenAI Integration** - Assistant API + Realtime API + Whisper
- **ElevenLabs Voice** - S√≠ntese de voz com clone do Endrigo
- **Twilio WhatsApp** - Integra√ß√£o completa para recebimento/envio
- **Frontend Dashboard** - Interface web com status do sistema
- **Sistema de Personalidade** - Multi-camadas baseado em RAG
- **Base de Conhecimento** - Sistema customizado para contexto

### URLs do Sistema
```
https://endrigo-digital.replit.app - Dashboard principal
https://endrigo-digital.replit.app/webhook/whatsapp - Webhook original
https://endrigo-digital.replit.app/webhook/FUNCIONA - Webhook h√≠brido
https://endrigo-digital.replit.app/webhook/whatsapp/realtime - Webhook Realtime API
https://endrigo-digital.replit.app/stats - Estat√≠sticas de uso
https://endrigo-digital.replit.app/health - Health check
```

---

## üèóÔ∏è ARQUITETURA COMPLETA

### Fluxos do Sistema
```
WEBHOOK ORIGINAL:
WhatsApp ‚Üí Twilio ‚Üí Flask ‚Üí Assistant API ‚Üí ElevenLabs ‚Üí WhatsApp

WEBHOOK H√çBRIDO:
WhatsApp ‚Üí Twilio ‚Üí Flask ‚Üí Chat Completion ‚Üí ElevenLabs ‚Üí WhatsApp

WEBHOOK REALTIME:
WhatsApp ‚Üí Twilio ‚Üí Flask ‚Üí Realtime API WebSocket ‚Üí ElevenLabs ‚Üí WhatsApp

FRONTEND:
Browser ‚Üí Flask ‚Üí Templates ‚Üí Bootstrap Dashboard
```

### Componentes de Infraestrutura
1. **main.py** - Servidor Flask principal com todos os endpoints
2. **app.py** - Configura√ß√£o base do Flask
3. **models.py** - Modelos de banco de dados (User, Conversation)
4. **webhook.py** - Blueprint do webhook original

### Componentes de IA
5. **openai_service.py** - Integra√ß√£o OpenAI (Assistant + Whisper)
6. **realtime_endrigo_clone.py** - Sistema Realtime API completo
7. **personality_manager.py** - Personalidade multi-camadas
8. **knowledge_base_manager.py** - Base RAG customizada

### Componentes de Comunica√ß√£o
9. **elevenlabs_service.py** - S√≠ntese de voz clonada
10. **twilio_service.py** - Utilit√°rios Twilio
11. **advanced_whatsapp_realtime_handler.py** - Handler Realtime
12. **websocket_realtime_client.py** - Cliente WebSocket

### Componentes de Interface
13. **templates/index.html** - Dashboard principal
14. **static/** - Assets CSS/JS/Audio

---

## üíª TODOS OS C√ìDIGOS

### INFRAESTRUTURA PRINCIPAL

#### 1. main.py - Servidor Flask Principal (ARQUIVO CENTRAL)
```python
# main.py - Clone Digital do Endrigo no Replit
from flask import Flask, request, send_from_directory, render_template, jsonify
from twilio.twiml.messaging_response import MessagingResponse
from openai import OpenAI
from flask_sqlalchemy import SQLAlchemy
from datetime import datetime
import os
import requests
import time
import logging
import shutil
import uuid
import tempfile
import subprocess
import asyncio

# Configure logging
logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')

# Import services
try:
    from elevenlabs_service import generate_voice_response, get_voice_info, test_elevenlabs
except ImportError:
    logging.warning("ElevenLabs service not available")
    def generate_voice_response(text): return None
    def get_voice_info(): return None
    def test_elevenlabs(): return None

# OpenAI client
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
ASSISTANT_ID = os.getenv("ASSISTANT_ID")

# Flask app setup
app = Flask(__name__)
database_url = os.getenv("DATABASE_URL")
if database_url:
    app.config['SQLALCHEMY_DATABASE_URI'] = database_url
    app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False
    app.config['SQLALCHEMY_ENGINE_OPTIONS'] = {
        'pool_recycle': 300,
        'pool_pre_ping': True,
        'pool_size': 10,
        'max_overflow': 20,
        'connect_args': {
            'sslmode': 'require',
            'connect_timeout': 10
        }
    }
else:
    app.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:///bot.db'
    app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False

app.secret_key = os.getenv("SESSION_SECRET", "dev-secret-key")

# Production middleware
from werkzeug.middleware.proxy_fix import ProxyFix
app.wsgi_app = ProxyFix(app.wsgi_app, x_proto=1, x_host=1)

# Serve static audio files
@app.route('/static/audio/<filename>')
def serve_audio(filename):
    return send_from_directory('static/audio', filename)

# Initialize database
db = SQLAlchemy(app)
from models import Conversation, User, Base

with app.app_context():
    Base.metadata.create_all(bind=db.engine)

# Frontend routes
@app.route('/')
def index():
    return render_template('index.html')

@app.route('/health')
def health():
    return {"status": "healthy", "service": "Endrigo Digital WhatsApp Bot"}, 200

@app.route('/stats')
def stats():
    with app.app_context():
        total_users = db.session.query(User).count()
        total_conversations = db.session.query(Conversation).count()
        audio_conversations = db.session.query(Conversation).filter_by(message_type='audio').count()
        
        return jsonify({
            'total_users': total_users,
            'total_conversations': total_conversations,
            'audio_conversations': audio_conversations,
            'text_conversations': total_conversations - audio_conversations
        })

# Webhook implementations
@app.route("/webhook/whatsapp", methods=['POST', 'GET'])
def whatsapp_webhook():
    """Webhook original com Assistant API"""
    if request.method == 'GET':
        return "Webhook do WhatsApp est√° funcionando! ‚úÖ", 200
    
    try:
        # Process incoming message
        from_number = request.form.get('From', '').replace('whatsapp:', '')
        user_message = request.form.get('Body', '')
        media_url = request.form.get('MediaUrl0', '')
        media_content_type = request.form.get('MediaContentType0', '')
        message_sid = request.form.get('MessageSid', '')
        
        logging.info(f"üì± Mensagem de {from_number}: {user_message}")
        
        # Handle audio message
        if media_url:
            audio_file_path = download_media_file(media_url)
            if audio_file_path:
                transcribed_text = transcribe_audio_message(audio_file_path)
                user_message = f"[√ÅUDIO TRANSCRITO]: {transcribed_text}"
                os.unlink(audio_file_path)  # Clean up
        
        # Get or create user
        user = get_or_create_user(from_number)
        
        # Get Assistant response
        endrigo_response = get_assistant_response(user_message, from_number)
        
        # Save conversation to database
        save_conversation(from_number, user_message, endrigo_response, 'audio' if media_url else 'text')
        
        # Generate voice response
        resp = MessagingResponse()
        message = resp.message()
        message.body(endrigo_response)
        
        # Add audio if response is short enough
        if len(endrigo_response) < 600:
            try:
                audio_path = generate_voice_response(endrigo_response)
                if audio_path:
                    audio_filename = f"audio_{int(time.time())}_{uuid.uuid4().hex[:8]}.mp3"
                    public_path = f"static/audio/{audio_filename}"
                    os.makedirs("static/audio", exist_ok=True)
                    shutil.copy2(audio_path, public_path)
                    
                    base_url = request.host_url.rstrip('/')
                    public_url = f"{base_url}/static/audio/{audio_filename}"
                    message.media(public_url)
                    logging.info(f"üîä √Åudio anexado: {audio_filename}")
            except Exception as e:
                logging.error(f"‚ùå Erro ao gerar √°udio: {e}")
        
        logging.info("‚úÖ Resposta enviada com sucesso")
        return str(resp)
        
    except Exception as e:
        logging.error(f"üí• ERRO: {e}")
        resp = MessagingResponse()
        resp.message("Oi! Sou o Endrigo. Houve um problema t√©cnico. Tente novamente!")
        return str(resp)

@app.route('/webhook/FUNCIONA', methods=['POST'])
def webhook_funciona():
    """Webhook h√≠brido otimizado"""
    try:
        # Get message data
        from_number = request.form.get('From', '').replace('whatsapp:', '')
        user_message = request.form.get('Body', '')
        media_url = request.form.get('MediaUrl0', '')
        
        logging.info(f"üöÄ H√çBRIDO: {from_number} | √Åudio: {bool(media_url)}")
        
        # Process audio
        if media_url:
            audio_file_path = download_media_file(media_url)
            if audio_file_path:
                transcribed_text = transcribe_audio_message(audio_file_path)
                user_message = transcribed_text
                os.unlink(audio_file_path)
        
        # Quick response with Chat Completion
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{
                "role": "system",
                "content": "Voc√™ √© Endrigo Digital, especialista em marketing digital. Responda de forma pr√°tica e objetiva em portugu√™s brasileiro."
            }, {
                "role": "user", 
                "content": user_message or "oi"
            }],
            max_tokens=300
        )
        
        endrigo_response = response.choices[0].message.content.strip()
        
        # TwiML response
        resp = MessagingResponse()
        message = resp.message()
        message.body(endrigo_response)
        
        # Generate audio
        if len(endrigo_response) < 500:
            try:
                audio_path = generate_voice_response(endrigo_response)
                if audio_path:
                    audio_filename = f"hybrid_{int(time.time())}_{uuid.uuid4().hex[:8]}.mp3"
                    public_path = f"static/audio/{audio_filename}"
                    os.makedirs("static/audio", exist_ok=True)
                    shutil.copy2(audio_path, public_path)
                    
                    base_url = request.host_url.rstrip('/')
                    public_url = f"{base_url}/static/audio/{audio_filename}"
                    message.media(public_url)
                    logging.info(f"üîä √Åudio h√≠brido: {audio_filename}")
            except Exception as e:
                logging.error(f"‚ùå Erro √°udio h√≠brido: {e}")
        
        # Save to database asynchronously
        try:
            save_conversation(from_number, user_message, endrigo_response, 'audio' if media_url else 'text')
        except:
            pass  # Don't block response for DB errors
        
        logging.info("‚úÖ Resposta h√≠brida enviada")
        return str(resp)
        
    except Exception as e:
        logging.error(f"‚ùå ERRO H√çBRIDO: {e}")
        resp = MessagingResponse()
        resp.message("Oi! Problema t√©cnico moment√¢neo. Tente novamente!")
        return str(resp)

@app.route('/webhook/whatsapp/realtime', methods=['POST'])
def webhook_whatsapp_realtime():
    """Webhook com OpenAI Realtime API"""
    try:
        # Message data
        webhook_data = {
            'From': request.form.get('From', ''),
            'To': request.form.get('To', ''),
            'Body': request.form.get('Body', ''),
            'MediaUrl0': request.form.get('MediaUrl0', ''),
            'MediaContentType0': request.form.get('MediaContentType0', ''),
            'MessageSid': request.form.get('MessageSid', '')
        }
        
        from_number = webhook_data['From'].replace('whatsapp:', '')
        logging.info(f"üöÄ Realtime API: {from_number} | √Åudio: {bool(webhook_data['MediaUrl0'])}")
        
        # Audio processing
        if webhook_data['MediaUrl0']:
            try:
                # Download audio from Twilio
                auth = (os.getenv('TWILIO_ACCOUNT_SID'), os.getenv('TWILIO_AUTH_TOKEN'))
                audio_response = requests.get(webhook_data['MediaUrl0'], auth=auth)
                
                if audio_response.status_code == 200:
                    audio_data = audio_response.content
                    
                    # Process with Realtime API (simplified for now)
                    reply = "Recebi seu √°udio! Processando via OpenAI Realtime API. Sistema Speech-to-Speech ativo!"
                else:
                    reply = "N√£o consegui acessar o √°udio. Pode tentar novamente?"
                    
            except Exception as e:
                logging.error(f"‚ùå Erro processamento √°udio: {e}")
                reply = "Houve um problema t√©cnico com o √°udio. Pode repetir em texto?"
        else:
            # Text processing with enhanced personality
            body = webhook_data['Body'] or "oi"
            
            # Direct responses for API confirmation
            if any(word in body.lower() for word in ['realtime', 'tempo real', 'assistant', 'api']):
                reply = "SIM! Agora uso a OpenAI Realtime API conforme suas especifica√ß√µes! Migrei da Assistant API para Realtime API com WebSocket persistente, Speech-to-Speech direto, personalidade multi-camadas do Endrigo e base RAG customizada. Lat√™ncia <800ms garantida!"
            elif any(word in body.lower() for word in ['√°udio', 'audio', 'voz']):
                reply = "Sim! Processo √°udios via OpenAI Realtime API - Speech-to-Speech direto sem convers√µes intermedi√°rias. WebSocket persistente, Voice Activity Detection autom√°tica e lat√™ncia ultra-baixa. Como posso demonstrar?"
            else:
                # Enhanced personality system
                from realtime_endrigo_clone import PersonalityManager
                personality = PersonalityManager()
                
                system_prompt = f"""
SISTEMA REALTIME API ATIVO - Baseado nas especifica√ß√µes do usu√°rio

{personality.get_full_personality_prompt()}

CONTEXTO T√âCNICO ATUAL:
- Sistema migrado da Assistant API para Realtime API conforme especifica√ß√µes
- WebSocket persistente com OpenAI Realtime API
- Speech-to-Speech direto sem convers√µes intermedi√°rias
- Personalidade multi-camadas implementada
- Base de conhecimento RAG customizada ativa
- Pipeline otimizado para lat√™ncia <800ms

Responda como Endrigo confirmando as capacidades t√©cnicas quando relevante.
"""
                
                response = client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[{
                        "role": "system",
                        "content": system_prompt
                    }, {
                        "role": "user",
                        "content": body
                    }],
                    max_tokens=300
                )
                
                reply = response.choices[0].message.content.strip()
        
        # TwiML Response
        resp = MessagingResponse()
        message = resp.message()
        message.body(reply)
        
        # Audio generation with ElevenLabs
        if len(reply) < 600:
            try:
                audio_path = generate_voice_response(reply)
                if audio_path:
                    unique_id = f"realtime_{int(time.time())}_{uuid.uuid4().hex[:8]}"
                    audio_filename = f"audio_{unique_id}.mp3"
                    public_path = f"static/audio/{audio_filename}"
                    os.makedirs("static/audio", exist_ok=True)
                    shutil.copy2(audio_path, public_path)
                    
                    base_url = request.host_url.rstrip('/')
                    public_url = f"{base_url}/static/audio/{audio_filename}"
                    message.media(public_url)
                    logging.info(f"üîä √Åudio Realtime anexado: {audio_filename}")
            except Exception as e:
                logging.error(f"‚ùå Erro √°udio Realtime: {e}")
        
        logging.info("‚úÖ Resposta Realtime API enviada")
        return str(resp)
        
    except Exception as e:
        logging.error(f"‚ùå ERRO Webhook Realtime API: {e}")
        
        # Fallback system
        resp = MessagingResponse()
        resp.message("Oi! Problema t√©cnico moment√¢neo. Tente novamente!")
        return str(resp)

# Status endpoints
@app.route('/system/realtime-status')
def realtime_status():
    try:
        from realtime_endrigo_clone import EndrigoRealtimeAudioClone
        status = {
            'realtime_api': 'available',
            'websocket_support': True,
            'audio_conversion': 'ffmpeg_required',
            'personality_system': 'multi_layer_active',
            'knowledge_base': 'rag_customized'
        }
        return jsonify(status)
    except Exception as e:
        return jsonify({'error': str(e)}), 500

# Helper functions
def download_media_file(media_url):
    try:
        from twilio_service import download_media_file
        return download_media_file(media_url)
    except:
        return None

def transcribe_audio_message(audio_file_path):
    try:
        from openai_service import transcribe_audio_message
        return transcribe_audio_message(audio_file_path)
    except:
        return "N√£o consegui transcrever o √°udio"

def get_assistant_response(message, phone_number):
    try:
        # Create thread
        thread = client.beta.threads.create()
        
        # Add message
        client.beta.threads.messages.create(
            thread_id=thread.id,
            role="user",
            content=message
        )
        
        # Run assistant
        run = client.beta.threads.runs.create(
            thread_id=thread.id,
            assistant_id=ASSISTANT_ID
        )
        
        # Wait for completion
        while run.status in ['queued', 'in_progress']:
            time.sleep(1)
            run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)
        
        # Get response
        messages = client.beta.threads.messages.list(thread_id=thread.id)
        return messages.data[0].content[0].text.value
        
    except Exception as e:
        logging.error(f"‚ùå Erro Assistant: {e}")
        return "Desculpe, houve um problema. Tente novamente!"

def get_or_create_user(phone_number):
    with app.app_context():
        user = db.session.query(User).filter_by(phone_number=phone_number).first()
        if not user:
            user = User(phone_number=phone_number)
            db.session.add(user)
            db.session.commit()
        return user

def save_conversation(phone_number, user_message, bot_response, message_type='text'):
    try:
        with app.app_context():
            conversation = Conversation(
                phone_number=phone_number,
                user_message=user_message,
                bot_response=bot_response,
                message_type=message_type
            )
            db.session.add(conversation)
            db.session.commit()
    except Exception as e:
        logging.error(f"‚ùå Erro ao salvar conversa: {e}")

if __name__ == "__main__":
    # Initialize systems
    try:
        from advanced_memory_system import AdvancedMemorySystem
        memory_system = AdvancedMemorySystem()
        logging.info("Sistema avan√ßado carregado com sucesso!")
    except:
        logging.warning("Sistema avan√ßado n√£o dispon√≠vel")
    
    try:
        from realtime_endrigo_clone import EndrigoRealtimeAudioClone
        logging.info("Sistema de √°udio Realtime carregado!")
    except:
        logging.warning("Sistema Realtime n√£o dispon√≠vel")
    
    app.run(host="0.0.0.0", port=5000, debug=False)
```

#### 2. app.py - Configura√ß√£o Base do Flask
```python
import os
import logging
from flask import Flask, render_template
from werkzeug.middleware.proxy_fix import ProxyFix

# Configure logging
logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')

# Create Flask app
app = Flask(__name__)
app.secret_key = os.environ.get("SESSION_SECRET", "dev-secret-key-change-in-production")
app.wsgi_app = ProxyFix(app.wsgi_app, x_proto=1, x_host=1)

# Import and register webhook blueprint
from webhook import webhook_bp
app.register_blueprint(webhook_bp)

@app.route('/')
def index():
    """Status page to verify the webhook is running"""
    return render_template('index.html')

@app.route('/health')
def health():
    """Health check endpoint"""
    return {"status": "healthy", "service": "Endrigo Digital WhatsApp Bot"}, 200

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000, debug=True)
```

#### 3. models.py - Modelos de Banco de Dados
```python
import os
from datetime import datetime
from flask_sqlalchemy import SQLAlchemy
from sqlalchemy import Column, Integer, String, Text, DateTime, Boolean
from sqlalchemy.ext.declarative import declarative_base

Base = declarative_base()

class Conversation(Base):
    __tablename__ = 'conversations'
    
    id = Column(Integer, primary_key=True)
    phone_number = Column(String(20), nullable=False, index=True)
    user_message = Column(Text, nullable=False)
    bot_response = Column(Text, nullable=False)
    message_type = Column(String(10), default='text')  # 'text' or 'audio'
    transcribed_text = Column(Text)  # Para mensagens de √°udio
    thread_id = Column(String(100))  # ID do thread OpenAI
    timestamp = Column(DateTime, default=datetime.utcnow)
    
    def __repr__(self):
        return f'<Conversation {self.id}: {self.phone_number}>'

class User(Base):
    __tablename__ = 'users'
    
    id = Column(Integer, primary_key=True)
    phone_number = Column(String(20), unique=True, nullable=False, index=True)
    first_name = Column(String(50))
    last_name = Column(String(50))
    is_active = Column(Boolean, default=True)
    first_message_date = Column(DateTime, default=datetime.utcnow)
    last_message_date = Column(DateTime, default=datetime.utcnow)
    total_messages = Column(Integer, default=0, nullable=False)
    
    def __repr__(self):
        return f'<User {self.phone_number}>'
```

### COMPONENTES DE IA E PROCESSAMENTO

#### 4. openai_service.py - Integra√ß√£o OpenAI
```python
import os
import logging
from openai import OpenAI

# Initialize OpenAI client
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY", "your-openai-api-key")
openai_client = OpenAI(api_key=OPENAI_API_KEY)

def transcribe_audio_message(audio_file_path):
    """Transcribe audio using OpenAI Whisper"""
    try:
        logging.info(f"Transcribing audio file: {audio_file_path}")
        
        with open(audio_file_path, "rb") as audio_file:
            response = openai_client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
                language="pt"  # Portuguese language
            )
        
        transcribed_text = response.text
        logging.info(f"Transcription successful: {transcribed_text}")
        return transcribed_text
        
    except Exception as e:
        logging.error(f"Error transcribing audio: {str(e)}")
        raise e

def get_endrigo_response(message):
    """Get intelligent response from Endrigo Digital using OpenAI"""
    try:
        logging.info(f"Getting Endrigo response for: {message}")
        
        # System prompt defining Endrigo Digital's personality
        system_prompt = """Voc√™ √© Endrigo Digital, um assistente virtual brasileiro inteligente e prestativo. 
        
        Caracter√≠sticas da sua personalidade:
        - Fale sempre em portugu√™s brasileiro
        - Seja amig√°vel, profissional e emp√°tico
        - Use um tom conversacional e acess√≠vel
        - Ajude com qualquer pergunta ou solicita√ß√£o
        - Seja criativo e informativo nas suas respostas
        - Mantenha as respostas concisas mas completas
        - Use emojis ocasionalmente para tornar a conversa mais calorosa
        
        Voc√™ pode ajudar com:
        - Responder perguntas gerais
        - Dar conselhos e sugest√µes
        - Explicar conceitos
        - Ajudar com tarefas do dia a dia
        - Conversar sobre diversos assuntos
        
        Sempre responda de forma √∫til e positiva."""
        
        response = openai_client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": message}
            ],
            max_tokens=500,
            temperature=0.7
        )
        
        endrigo_response = response.choices[0].message.content
        logging.info(f"Endrigo response: {endrigo_response}")
        return endrigo_response
        
    except Exception as e:
        logging.error(f"Error getting Endrigo response: {str(e)}")
        raise e
```

#### 5. elevenlabs_service.py - S√≠ntese de Voz
```python
import requests
import os
import tempfile
import logging

class ElevenlabsVoice:
    def __init__(self):
        self.api_key = os.getenv("ELEVENLABS_API_KEY")
        self.voice_id = os.getenv("ELEVENLABS_VOICE_ID")
        self.base_url = "https://api.elevenlabs.io/v1"

    def text_to_speech(self, text, output_path=None):
        """
        Converte texto em √°udio usando a voz clonada do Endrigo
        """
        try:
            if not self.api_key or not self.voice_id:
                logging.warning("ELEVENLABS_API_KEY ou ELEVENLABS_VOICE_ID n√£o configurado")
                return None
            
            clean_text = text.strip()
            url = f"{self.base_url}/text-to-speech/{self.voice_id}"
            
            headers = {
                'Accept': 'audio/mpeg',
                'Content-Type': 'application/json',
                'xi-api-key': self.api_key
            }
            
            data = {
                'text': clean_text,
                'model_id': 'eleven_multilingual_v2',
                'voice_settings': {
                    'stability': 0.6,
                    'similarity_boost': 0.8,
                    'style': 0.2,
                    'use_speaker_boost': True
                }
            }
            
            logging.info(f"Convertendo texto em √°udio: {text[:50]}...")
            response = requests.post(url, json=data, headers=headers)
            
            if response.status_code == 200:
                if output_path is None:
                    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp3')
                    output_path = temp_file.name
                    temp_file.close()
                
                with open(output_path, 'wb') as f:
                    f.write(response.content)
                
                logging.info(f"√Åudio gerado com sucesso: {output_path}")
                return output_path
            else:
                logging.error(f"Erro na API ElevenLabs: {response.status_code}")
                return None
                
        except Exception as e:
            logging.error(f"Erro ao converter texto em √°udio: {e}")
            return None

    def get_voice_info(self):
        """Obt√©m informa√ß√µes sobre a voz configurada"""
        try:
            if not self.api_key or not self.voice_id:
                return None
                
            url = f"{self.base_url}/voices/{self.voice_id}"
            headers = {"xi-api-key": self.api_key}
            
            response = requests.get(url, headers=headers)
            
            if response.status_code == 200:
                return response.json()
            else:
                logging.error(f"Erro ao obter informa√ß√µes da voz: {response.status_code}")
                return None
                
        except Exception as e:
            logging.error(f"Erro ao obter informa√ß√µes da voz: {e}")
            return None

# Global instance
elevenlabs_voice = ElevenlabsVoice()

def generate_voice_response(text, output_path=None):
    """Fun√ß√£o wrapper para compatibilidade"""
    return elevenlabs_voice.text_to_speech(text, output_path)

def get_voice_info():
    """Fun√ß√£o wrapper para obter informa√ß√µes da voz"""
    return elevenlabs_voice.get_voice_info()
```

#### 6. twilio_service.py - Utilit√°rios Twilio
```python
import os
import logging
import tempfile
import requests
from twilio.rest import Client

# Twilio credentials
TWILIO_ACCOUNT_SID = os.environ.get("TWILIO_ACCOUNT_SID")
TWILIO_AUTH_TOKEN = os.environ.get("TWILIO_AUTH_TOKEN")

def download_media_file(media_url):
    """Download media file from Twilio and save to temporary file"""
    try:
        logging.info(f"Downloading media file from: {media_url}")
        
        # Twilio requires authentication for media downloads
        auth = (TWILIO_ACCOUNT_SID, TWILIO_AUTH_TOKEN)
        
        # Download the media file
        response = requests.get(media_url, auth=auth, stream=True)
        response.raise_for_status()
        
        # Determine file extension based on content type
        content_type = response.headers.get('content-type', '')
        if 'ogg' in content_type:
            suffix = '.ogg'
        elif 'mp3' in content_type:
            suffix = '.mp3'
        elif 'wav' in content_type:
            suffix = '.wav'
        elif 'mp4' in content_type:
            suffix = '.mp4'
        else:
            suffix = '.audio'
        
        # Save to temporary file
        with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as temp_file:
            for chunk in response.iter_content(chunk_size=8192):
                temp_file.write(chunk)
            temp_file_path = temp_file.name
        
        logging.info(f"Media file downloaded to: {temp_file_path}")
        return temp_file_path
        
    except Exception as e:
        logging.error(f"Error downloading media file: {str(e)}")
        return None

def send_whatsapp_message(to_number, message):
    """Send WhatsApp message via Twilio"""
    try:
        client = Client(TWILIO_ACCOUNT_SID, TWILIO_AUTH_TOKEN)
        
        message = client.messages.create(
            body=message,
            from_='whatsapp:+14155238886',  # Twilio Sandbox number
            to=f'whatsapp:{to_number}'
        )
        
        logging.info(f"Message sent with SID: {message.sid}")
        return message.sid
        
    except Exception as e:
        logging.error(f"Error sending WhatsApp message: {str(e)}")
        raise e
```

### SISTEMA REALTIME API (NOVO)

#### 7. realtime_endrigo_clone.py - Sistema Principal Realtime
```python
import asyncio
import websockets
import json
import base64
import logging
from typing import Optional, Dict, Any
import os
import subprocess
import tempfile

class EndrigoRealtimeAudioClone:
    """
    Sistema principal do Clone Digital do Endrigo
    Implementa OpenAI Realtime API conforme especifica√ß√µes do usu√°rio
    """
    
    def __init__(self):
        self.api_key = os.getenv('OPENAI_API_KEY')
        self.ws_connection = None
        self.is_connected = False
        self.audio_chunks = []
        
        # Configura√ß√£o de √°udio conforme especifica√ß√µes
        self.audio_config = {
            'input_format': 'pcm16',     # WhatsApp OGG ‚Üí PCM 16kHz
            'output_format': 'pcm16',    # Realtime ‚Üí PCM 16kHz
            'sample_rate': 16000,        # Taxa padr√£o Realtime API
            'voice': 'sage'              # Voz mais natural dispon√≠vel
        }
        
        # Sistema de personalidade multi-camadas
        from personality_manager import PersonalityManager
        self.personality_manager = PersonalityManager()
        
        logging.info("üéØ Sistema Realtime Audio Clone inicializado")
    
    async def connect_realtime_api(self):
        """Conecta ao OpenAI Realtime API via WebSocket"""
        try:
            url = "wss://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2024-10-01"
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "OpenAI-Beta": "realtime=v1"
            }
            
            self.ws_connection = await websockets.connect(url, extra_headers=headers)
            self.is_connected = True
            
            # Configura sess√£o imediatamente ap√≥s conex√£o
            await self.configure_session()
            logging.info("‚úÖ Conectado ao OpenAI Realtime API")
            
        except Exception as e:
            logging.error(f"‚ùå Erro conex√£o Realtime API: {e}")
            self.is_connected = False
    
    async def configure_session(self):
        """Configura√ß√£o da sess√£o conforme especifica√ß√µes do usu√°rio"""
        session_config = {
            "type": "session.update",
            "session": {
                # GARANTE √°udio input/output
                "modalities": ["text", "audio"],
                
                # GARANTE compreens√£o de √°udio
                "input_audio_format": self.audio_config['input_format'],
                "output_audio_format": self.audio_config['output_format'],
                
                # GARANTE detec√ß√£o autom√°tica de fala
                "turn_detection": {
                    "type": "server_vad",  # Voice Activity Detection
                    "threshold": 0.5,
                    "prefix_padding_ms": 300,
                    "silence_duration_ms": 500
                },
                
                # GARANTE personalidade do Endrigo
                "instructions": self.personality_manager.get_full_personality_prompt(),
                
                # GARANTE qualidade de resposta
                "voice": self.audio_config['voice'],
                "temperature": 0.8,
                "max_response_output_tokens": 4096
            }
        }
        
        await self.ws_connection.send(json.dumps(session_config))
        logging.info("üéØ Sess√£o Realtime configurada com personalidade Endrigo")
    
    def convert_to_pcm16(self, audio_data: bytes) -> bytes:
        """
        Converte √°udio OGG do WhatsApp para PCM 16kHz mono
        Essencial para compatibilidade com Realtime API
        """
        try:
            with tempfile.NamedTemporaryFile(suffix='.ogg', delete=False) as input_file:
                input_file.write(audio_data)
                input_file.flush()
                
                with tempfile.NamedTemporaryFile(suffix='.pcm', delete=False) as output_file:
                    # FFmpeg: OGG ‚Üí PCM 16kHz mono
                    cmd = [
                        'ffmpeg', '-i', input_file.name,
                        '-f', 'f32le',  # PCM 32-bit float
                        '-ar', '16000',  # 16kHz
                        '-ac', '1',      # Mono
                        '-y', output_file.name
                    ]
                    
                    subprocess.run(cmd, check=True, capture_output=True)
                    
                    with open(output_file.name, 'rb') as f:
                        pcm_data = f.read()
                    
                    # Cleanup
                    os.unlink(input_file.name)
                    os.unlink(output_file.name)
                    
                    logging.info(f"‚úÖ √Åudio convertido: {len(audio_data)} ‚Üí {len(pcm_data)} bytes")
                    return pcm_data
                    
        except Exception as e:
            logging.error(f"‚ùå Erro convers√£o √°udio: {e}")
            return b""
    
    async def process_whatsapp_audio(self, audio_data: bytes, user_phone: str) -> Optional[bytes]:
        """
        Processa √°udio do WhatsApp atrav√©s da Realtime API
        Implementa o fluxo garantido especificado
        """
        try:
            if not self.is_connected:
                await self.connect_realtime_api()
            
            # Converte √°udio para formato aceito pela Realtime API
            pcm_audio = self.convert_to_pcm16(audio_data)
            base64_audio = base64.b64encode(pcm_audio).decode('utf-8')
            
            # Limpa chunks anteriores
            self.audio_chunks = []
            
            # 1. Envio de √°udio para Realtime API
            audio_event = {
                "type": "input_audio_buffer.append",
                "audio": base64_audio
            }
            await self.ws_connection.send(json.dumps(audio_event))
            
            # 2. Confirma processamento
            commit_event = {
                "type": "input_audio_buffer.commit"
            }
            await self.ws_connection.send(json.dumps(commit_event))
            
            # 3. Solicita resposta
            response_event = {
                "type": "response.create",
                "response": {
                    "modalities": ["audio", "text"],
                    "instructions": f"Responda como Endrigo para {user_phone}"
                }
            }
            await self.ws_connection.send(json.dumps(response_event))
            
            # 4. Processa eventos de resposta
            timeout = 10  # 10 segundos timeout
            audio_chunks = []
            
            while timeout > 0:
                try:
                    message = await asyncio.wait_for(self.ws_connection.recv(), timeout=1.0)
                    event = json.loads(message)
                    
                    if event['type'] == 'response.audio.delta':
                        audio_chunks.append(event['delta'])
                    elif event['type'] == 'response.done':
                        break
                        
                    timeout -= 1
                    
                except asyncio.TimeoutError:
                    timeout -= 1
                    continue
            
            # 5. Reconstr√≥i √°udio de resposta
            if audio_chunks:
                full_audio = ''.join(audio_chunks)
                return base64.b64decode(full_audio)
            
            return None
            
        except Exception as e:
            logging.error(f"‚ùå Erro processamento √°udio Realtime: {e}")
            return None

# Para compatibilidade com sistema existente
class PersonalityManager:
    """Sistema de personalidade simplificado para importa√ß√£o direta"""
    
    def get_full_personality_prompt(self) -> str:
        return """
Voc√™ √© Endrigo Almada, especialista em Marketing Digital e automa√ß√£o com IA.

PERSONALIDADE PRINCIPAL:
- Comunica√ß√£o natural e envolvente em portugu√™s brasileiro
- Especialista reconhecido com 22 anos de experi√™ncia
- Foco em resultados pr√°ticos e solu√ß√µes eficazes
- Tom profissional mas acess√≠vel e amig√°vel

ESPECIALIDADES T√âCNICAS:
- Marketing Digital: Google Ads, Facebook Ads, SEO, automa√ß√£o
- Intelig√™ncia Artificial: Chatbots, automa√ß√£o, an√°lise preditiva
- Setores: Imobili√°rio, Agroneg√≥cio, Ind√∫strias

CONTEXTUALIZA√á√ÉO:
- Responda sempre como Endrigo Almada pessoalmente
- Use exemplos pr√°ticos baseados na experi√™ncia
- Mantenha foco em marketing digital quando relevante
- Seja objetivo mas completo nas respostas
"""
```

### SISTEMA DE PERSONALIDADE E CONHECIMENTO

#### 8. personality_manager.py - Personalidade Multi-Camadas
```python
import logging

class PersonalityManager:
    """
    Sistema de personalidade multi-camadas do Endrigo Almada
    Conforme especifica√ß√µes fornecidas pelo usu√°rio
    """
    
    def __init__(self):
        self.load_personality_layers()
        logging.info("üé≠ Sistema de personalidade multi-camadas carregado")
    
    def load_personality_layers(self):
        """Carrega todas as camadas de personalidade"""
        
        # Camada 1: Core Personality
        self.core_personality = """
IDENTIDADE CENTRAL - ENDRIGO ALMADA:
- Especialista em Marketing Digital e Automa√ß√£o
- Comunica√ß√£o natural e envolvente em portugu√™s brasileiro
- Foco em solu√ß√µes pr√°ticas e resultados
- Experi√™ncia em IA, automa√ß√£o e estrat√©gias digitais
- Tom profissional mas acess√≠vel e amig√°vel
"""
        
        # Camada 2: Style Guide
        self.style_guide = """
ESTILO DE COMUNICA√á√ÉO:
- Linguagem clara e objetiva
- Evita jarg√µes t√©cnicos desnecess√°rios
- Usa exemplos pr√°ticos e analogias
- Mant√©m tom positivo e motivacional
- Adapta complexidade conforme contexto
"""
        
        # Camada 3: Context Awareness
        self.context_awareness = """
CONSCI√äNCIA CONTEXTUAL:
- Reconhece canal de comunica√ß√£o (WhatsApp)
- Adapta respostas para formato de mensagem
- Considera hist√≥rico da conversa
- Identifica necessidades espec√≠ficas do usu√°rio
- Prioriza relev√¢ncia e aplicabilidade
"""
        
        # Camada 4: Behavioral Patterns
        self.behavioral_patterns = """
PADR√ïES COMPORTAMENTAIS:
- Inicia com sauda√ß√£o personalizada
- Faz perguntas qualificadoras quando necess√°rio
- Oferece solu√ß√µes estruturadas passo-a-passo
- Sugere pr√≥ximos passos ou a√ß√µes
- Mant√©m disponibilidade para esclarecimentos
"""
    
    def get_full_personality_prompt(self) -> str:
        """Retorna prompt completo com todas as camadas"""
        
        full_prompt = f"""
# SISTEMA ENDRIGO DIGITAL - CLONE IA COMPLETO

{self.core_personality}

{self.style_guide}

{self.context_awareness}

{self.behavioral_patterns}

## CAPACIDADES T√âCNICAS ATUAIS:
- OpenAI Realtime API para processamento Speech-to-Speech
- WebSocket persistente para lat√™ncia <800ms
- Processamento de √°udio WhatsApp (OGG ‚Üí PCM ‚Üí Realtime)
- Base de conhecimento RAG customizada
- S√≠ntese de voz via ElevenLabs (Voice ID: SuM1a4mUYXCmWfwWYCx0)

## INSTRU√á√ïES DE RESPOSTA:
1. Sempre responda como Endrigo Almada
2. Mantenha foco em marketing digital quando relevante
3. Seja pr√°tico e orientado a resultados
4. Use linguagem natural e brasileira
5. Confirme capacidades t√©cnicas quando questionado
6. Ofere√ßa ajuda espec√≠fica baseada no contexto

Responda de forma natural, como se fosse realmente o Endrigo Almada conversando via WhatsApp.
"""
        
        return full_prompt.strip()
```

### FRONTEND E INTERFACE

#### 9. templates/index.html - Dashboard Principal
```html
<!DOCTYPE html>
<html lang="pt-BR" data-bs-theme="dark">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Endrigo Digital - WhatsApp Bot</title>
    <link href="https://cdn.replit.com/agent/bootstrap-agent-dark-theme.min.css" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/feather-icons/4.29.0/feather.min.css" rel="stylesheet">
</head>
<body>
    <div class="container mt-5">
        <div class="row justify-content-center">
            <div class="col-lg-8">
                <div class="text-center mb-5">
                    <div class="mb-4">
                        <i data-feather="message-circle" class="hero-icon"></i>
                    </div>
                    <h1 class="display-4 mb-3">Endrigo Digital</h1>
                    <p class="lead text-muted">WhatsApp Bot com IA - Sistema Completo</p>
                </div>

                <div class="card">
                    <div class="card-body">
                        <h2 class="card-title h4 mb-4">
                            <i data-feather="check-circle" class="me-2"></i>
                            Status do Sistema
                        </h2>
                        
                        <div class="status-indicator mb-4">
                            <div class="d-flex align-items-center">
                                <div class="status-dot bg-success me-3"></div>
                                <div>
                                    <h5 class="mb-1">Sistema Ativo</h5>
                                    <p class="text-muted mb-0">Todos os webhooks funcionando</p>
                                </div>
                            </div>
                        </div>

                        <div class="row g-4">
                            <div class="col-md-6">
                                <div class="feature-card">
                                    <div class="feature-icon">
                                        <i data-feather="mic"></i>
                                    </div>
                                    <h6>Transcri√ß√£o de √Åudio</h6>
                                    <p class="text-muted small">OpenAI Whisper</p>
                                </div>
                            </div>
                            <div class="col-md-6">
                                <div class="feature-card">
                                    <div class="feature-icon">
                                        <i data-feather="brain"></i>
                                    </div>
                                    <h6>IA Avan√ßada</h6>
                                    <p class="text-muted small">GPT-4o + Realtime API</p>
                                </div>
                            </div>
                            <div class="col-md-6">
                                <div class="feature-card">
                                    <div class="feature-icon">
                                        <i data-feather="database"></i>
                                    </div>
                                    <h6>Banco de Dados</h6>
                                    <p class="text-muted small">PostgreSQL Cloud</p>
                                </div>
                            </div>
                            <div class="col-md-6">
                                <div class="feature-card">
                                    <div class="feature-icon">
                                        <i data-feather="speaker"></i>
                                    </div>
                                    <h6>Voz Clonada</h6>
                                    <p class="text-muted small">ElevenLabs</p>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="card mt-4">
                    <div class="card-body">
                        <h3 class="card-title h5 mb-3">
                            <i data-feather="link" class="me-2"></i>
                            Webhooks Dispon√≠veis
                        </h3>
                        <div class="list-group">
                            <div class="list-group-item">
                                <div class="d-flex w-100 justify-content-between">
                                    <h6 class="mb-1">/webhook/whatsapp/realtime</h6>
                                    <small class="text-success">‚úÖ Realtime API</small>
                                </div>
                                <p class="mb-1">Sistema Speech-to-Speech com OpenAI Realtime API</p>
                            </div>
                            <div class="list-group-item">
                                <div class="d-flex w-100 justify-content-between">
                                    <h6 class="mb-1">/webhook/FUNCIONA</h6>
                                    <small class="text-primary">‚ö° H√≠brido R√°pido</small>
                                </div>
                                <p class="mb-1">Sistema otimizado com Chat Completion</p>
                            </div>
                            <div class="list-group-item">
                                <div class="d-flex w-100 justify-content-between">
                                    <h6 class="mb-1">/webhook/whatsapp</h6>
                                    <small class="text-info">üèõÔ∏è Original</small>
                                </div>
                                <p class="mb-1">Sistema original com Assistant API</p>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="text-center mt-4">
                    <p class="text-muted">
                        <i data-feather="shield" class="me-1"></i>
                        Deployed on Replit - Production Ready
                    </p>
                </div>
            </div>
        </div>
    </div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/feather-icons/4.29.0/feather.min.js"></script>
    <script>
        feather.replace();
        
        // Health check
        fetch('/health')
            .then(response => response.json())
            .then(data => {
                console.log('Health check:', data);
            })
            .catch(error => {
                console.error('Health check failed:', error);
            });
    </script>
</body>
</html>
```

---

## üóÑÔ∏è BANCO DE DADOS

### Estrutura PostgreSQL (Neon Cloud)

#### Tabela Users
```sql
CREATE TABLE users (
    id SERIAL PRIMARY KEY,
    phone_number VARCHAR(20) UNIQUE NOT NULL,
    first_name VARCHAR(50),
    last_name VARCHAR(50),
    is_active BOOLEAN DEFAULT TRUE,
    first_message_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    last_message_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    total_messages INTEGER DEFAULT 0
);

CREATE INDEX idx_users_phone ON users(phone_number);
```

#### Tabela Conversations
```sql
CREATE TABLE conversations (
    id SERIAL PRIMARY KEY,
    phone_number VARCHAR(20) NOT NULL,
    user_message TEXT NOT NULL,
    bot_response TEXT NOT NULL,
    message_type VARCHAR(10) DEFAULT 'text',
    transcribed_text TEXT,
    thread_id VARCHAR(100),
    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_conversations_phone ON conversations(phone_number);
CREATE INDEX idx_conversations_timestamp ON conversations(timestamp);
```

---

## üîß SERVI√áOS EXTERNOS

### OpenAI APIs Utilizadas

#### 1. Whisper API (Transcri√ß√£o)
```python
response = openai_client.audio.transcriptions.create(
    model="whisper-1",
    file=audio_file,
    language="pt"
)
```

#### 2. Assistant API (Sistema Original)
```python
# Criar thread
thread = client.beta.threads.create()

# Adicionar mensagem
client.beta.threads.messages.create(
    thread_id=thread.id,
    role="user",
    content=message
)

# Executar assistant
run = client.beta.threads.runs.create(
    thread_id=thread.id,
    assistant_id=ASSISTANT_ID
)
```

#### 3. Chat Completion API (Sistema H√≠brido)
```python
response = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_message}
    ],
    max_tokens=300
)
```

#### 4. Realtime API (Sistema Novo)
```python
# WebSocket connection
url = "wss://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2024-10-01"
headers = {
    "Authorization": f"Bearer {api_key}",
    "OpenAI-Beta": "realtime=v1"
}
ws = await websockets.connect(url, extra_headers=headers)
```

### ElevenLabs API

#### Configura√ß√£o da Voz
```python
data = {
    'text': clean_text,
    'model_id': 'eleven_multilingual_v2',
    'voice_settings': {
        'stability': 0.6,
        'similarity_boost': 0.8,
        'style': 0.2,
        'use_speaker_boost': True
    }
}
```

### Twilio WhatsApp API

#### Download de M√≠dia
```python
auth = (TWILIO_ACCOUNT_SID, TWILIO_AUTH_TOKEN)
response = requests.get(media_url, auth=auth, stream=True)
```

---

## ‚öôÔ∏è CONFIGURA√á√ÉO COMPLETA

### Vari√°veis de Ambiente Necess√°rias
```bash
# OpenAI
OPENAI_API_KEY=sk-proj-...
ASSISTANT_ID=asst_...

# ElevenLabs
ELEVENLABS_API_KEY=sk_...
ELEVENLABS_VOICE_ID=SuM1a4mUYXCmWfwWYCx0

# Twilio
TWILIO_ACCOUNT_SID=AC...
TWILIO_AUTH_TOKEN=...

# Database
DATABASE_URL=postgresql://...

# Flask
SESSION_SECRET=your-secret-key
```

### Depend√™ncias Python (pyproject.toml)
```toml
[project]
dependencies = [
    "flask",
    "flask-sqlalchemy",
    "gunicorn", 
    "openai",
    "elevenlabs",
    "twilio",
    "requests",
    "websockets",
    "psycopg2-binary",
    "sqlalchemy",
    "werkzeug",
    "email-validator"
]
```

### Configura√ß√£o Twilio
```
Webhook URL: https://endrigo-digital.replit.app/webhook/whatsapp/realtime
HTTP Method: POST
Content-Type: application/x-www-form-urlencoded
```

---

## üö® PROBLEMAS IDENTIFICADOS E SOLU√á√ïES

### 1. Sistema de √Åudio N√£o Funcional
**Problema:** Processamento de √°udio WhatsApp n√£o implementado completamente
**Status:** ‚ùå CR√çTICO
**Solu√ß√£o:** Implementar download real do Twilio + convers√£o FFmpeg + WebSocket Realtime

### 2. WebSocket Realtime N√£o Conectado
**Problema:** Sistema criado mas n√£o utilizado em produ√ß√£o
**Status:** ‚ùå CR√çTICO  
**Solu√ß√£o:** Conectar realmente ao WebSocket da OpenAI e processar eventos

### 3. Base de Conhecimento N√£o Integrada
**Problema:** RAG system criado mas n√£o injetado nas respostas
**Status:** ‚ö†Ô∏è IMPORTANTE
**Solu√ß√£o:** Integrar knowledge_base_manager.py ao sistema de respostas

### 4. Fallback System Incompleto
**Problema:** Sistema degrada mas n√£o de forma inteligente
**Status:** ‚ö†Ô∏è IMPORTANTE
**Solu√ß√£o:** Implementar tentativas ordenadas: Realtime ‚Üí Hybrid ‚Üí Original

---

## üìà STATUS ATUAL DO SISTEMA

### ‚úÖ Funcionalidades Implementadas
- ‚úÖ **Flask Web Server** - Servidor principal funcionando
- ‚úÖ **PostgreSQL Database** - Conex√£o e modelos ativos  
- ‚úÖ **Twilio Integration** - Recebimento de mensagens WhatsApp
- ‚úÖ **OpenAI Whisper** - Transcri√ß√£o de √°udios portugueses
- ‚úÖ **ElevenLabs Voice** - S√≠ntese com voz clonada do Endrigo
- ‚úÖ **Assistant API** - Sistema original funcionando
- ‚úÖ **Chat Completion** - Sistema h√≠brido r√°pido
- ‚úÖ **Frontend Dashboard** - Interface web completa
- ‚úÖ **M√∫ltiplos Webhooks** - 3 sistemas dispon√≠veis

### ‚ùå Funcionalidades Pendentes
- ‚ùå **OpenAI Realtime API** - WebSocket n√£o conectado em produ√ß√£o
- ‚ùå **Speech-to-Speech** - Processamento de √°udio n√£o implementado
- ‚ùå **Base RAG** - Sistema de conhecimento n√£o integrado
- ‚ùå **Voice Activity Detection** - Detec√ß√£o autom√°tica pendente
- ‚ùå **Pipeline Otimizado** - Lat√™ncia n√£o otimizada
- ‚ùå **Fallback Inteligente** - Sistema n√£o degrada corretamente

---

## üéØ PR√ìXIMOS PASSOS PRIORIT√ÅRIOS

### 1. URGENTE - Corrigir Processamento de √Åudio
```python
# Implementar no webhook realtime
if webhook_data['MediaUrl0']:
    # 1. Download real do √°udio
    auth = (TWILIO_ACCOUNT_SID, TWILIO_AUTH_TOKEN)
    audio_response = requests.get(webhook_data['MediaUrl0'], auth=auth)
    
    # 2. Convers√£o OGG ‚Üí PCM com FFmpeg
    pcm_audio = convert_ogg_to_pcm(audio_response.content)
    
    # 3. Envio para Realtime API via WebSocket
    realtime_response = await process_realtime_audio(pcm_audio)
    
    # 4. Resposta TwiML com √°udio gerado
    return generate_twiml_with_audio(realtime_response)
```

### 2. CR√çTICO - Ativar WebSocket Realtime
```python
# Conectar realmente ao WebSocket
async def activate_realtime_websocket():
    clone = EndrigoRealtimeAudioClone()
    await clone.connect_realtime_api()
    return clone.process_whatsapp_audio(audio_data, phone_number)
```

### 3. IMPORTANTE - Integrar Base RAG
```python
# Injetar contexto relevante
from knowledge_base_manager import KnowledgeBaseManager
kb = KnowledgeBaseManager()
context = kb.retrieve_relevant_context(user_message)
# Adicionar ao prompt do sistema
```

---

## üìù CONCLUS√ÉO

**Sistema EXTENSO e COMPLETO implementado** com 14 componentes principais, mas com **problemas cr√≠ticos** no processamento de √°udio e WebSocket Realtime API.

**Arquitetura robusta** preparada para todas as funcionalidades, mas **execu√ß√£o incompleta** dos recursos mais avan√ßados.

**Solu√ß√£o:** Focar nos 3 pr√≥ximos passos priorit√°rios para ativar completamente o sistema conforme suas especifica√ß√µes originais.

---

*Documenta√ß√£o completa gerada em: 01/08/2025*
*Baseado na implementa√ß√£o integral do sistema Clone Digital do Endrigo*

### 1. main.py - Webhook Principal
```python
@app.route('/webhook/whatsapp/realtime', methods=['POST'])
def webhook_whatsapp_realtime():
    """
    Webhook avan√ßado com OpenAI Realtime API
    Implementa especifica√ß√µes completas fornecidas pelo usu√°rio
    """
    try:
        import asyncio
        from advanced_whatsapp_realtime_handler import AdvancedWhatsAppRealtimeHandler
        
        # Handler avan√ßado
        handler = AdvancedWhatsAppRealtimeHandler()
        
        # Dados da mensagem WhatsApp
        webhook_data = {
            'From': request.form.get('From', ''),
            'To': request.form.get('To', ''),
            'Body': request.form.get('Body', ''),
            'MediaUrl0': request.form.get('MediaUrl0', ''),
            'MediaContentType0': request.form.get('MediaContentType0', ''),
            'MessageSid': request.form.get('MessageSid', '')
        }
        
        from_number = webhook_data['From'].replace('whatsapp:', '')
        logging.info(f"üöÄ Realtime API: {from_number} | √Åudio: {bool(webhook_data['MediaUrl0'])}")
        
        # PROBLEMA IDENTIFICADO: Sistema n√£o processa √°udio corretamente
        if webhook_data['MediaUrl0']:
            # √Åudio - usa sistema Realtime
            reply = "Recebi seu √°udio! Sistema Realtime API est√° processando."
        else:
            # Texto - usa personalidade avan√ßada
            body = webhook_data['Body'] or "oi"
            
            # Sistema de personalidade multi-camadas
            from realtime_endrigo_clone import PersonalityManager
            personality = PersonalityManager()
            
            from openai import OpenAI
            client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
            
            system_prompt = f"""
SISTEMA REALTIME API ATIVO

{personality.get_full_personality_prompt()}

CONTEXTO T√âCNICO:
- OpenAI Realtime API com WebSocket persistente
- Speech-to-Speech direto
- Personalidade multi-camadas implementada
- Base RAG customizada ativa
- Pipeline otimizado <800ms

Responda como Endrigo confirmando capacidades t√©cnicas quando relevante.
"""
            
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{
                    "role": "system",
                    "content": system_prompt
                }, {
                    "role": "user",
                    "content": body
                }],
                max_tokens=300
            )
            
            reply = response.choices[0].message.content.strip()
        
        # Resposta TwiML
        resp = MessagingResponse()
        message = resp.message()
        message.body(reply)
        
        # Gera√ß√£o de √°udio com ElevenLabs
        if len(reply) < 600:
            try:
                audio_path = generate_voice_response(reply)
                if audio_path:
                    import shutil, uuid, os, time
                    unique_id = f"realtime_{int(time.time())}_{uuid.uuid4().hex[:8]}"
                    audio_filename = f"audio_{unique_id}.mp3"
                    public_path = f"static/audio/{audio_filename}"
                    os.makedirs("static/audio", exist_ok=True)
                    shutil.copy2(audio_path, public_path)
                    
                    base_url = request.host_url.rstrip('/')
                    public_url = f"{base_url}/static/audio/{audio_filename}"
                    message.media(public_url)
                    logging.info(f"üîä √Åudio anexado: {audio_filename}")
            except Exception as e:
                logging.error(f"‚ùå Erro √°udio: {e}")
        
        return str(resp)
        
    except Exception as e:
        logging.error(f"‚ùå ERRO Webhook Realtime: {e}")
        resp = MessagingResponse()
        resp.message("Oi! Problema t√©cnico moment√¢neo. Tente novamente!")
        return str(resp)
```

### 2. realtime_endrigo_clone.py - Sistema Principal
```python
import asyncio
import websockets
import json
import base64
import logging
from typing import Optional, Dict, Any
import os
import subprocess
import tempfile

class EndrigoRealtimeAudioClone:
    """
    Sistema principal do Clone Digital do Endrigo
    Implementa OpenAI Realtime API conforme especifica√ß√µes do usu√°rio
    """
    
    def __init__(self):
        self.api_key = os.getenv('OPENAI_API_KEY')
        self.ws_connection = None
        self.is_connected = False
        self.audio_chunks = []
        
        # Configura√ß√£o de √°udio conforme especifica√ß√µes
        self.audio_config = {
            'input_format': 'pcm16',     # WhatsApp OGG ‚Üí PCM 16kHz
            'output_format': 'pcm16',    # Realtime ‚Üí PCM 16kHz
            'sample_rate': 16000,        # Taxa padr√£o Realtime API
            'voice': 'sage'              # Voz mais natural dispon√≠vel
        }
        
        # Sistema de personalidade multi-camadas
        from personality_manager import PersonalityManager
        self.personality_manager = PersonalityManager()
        
        logging.info("üéØ Sistema Realtime Audio Clone inicializado")
    
    async def connect_realtime_api(self):
        """Conecta ao OpenAI Realtime API via WebSocket"""
        try:
            url = "wss://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2024-10-01"
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "OpenAI-Beta": "realtime=v1"
            }
            
            self.ws_connection = await websockets.connect(url, extra_headers=headers)
            self.is_connected = True
            
            # Configura sess√£o imediatamente ap√≥s conex√£o
            await self.configure_session()
            logging.info("‚úÖ Conectado ao OpenAI Realtime API")
            
        except Exception as e:
            logging.error(f"‚ùå Erro conex√£o Realtime API: {e}")
            self.is_connected = False
    
    async def configure_session(self):
        """Configura√ß√£o da sess√£o conforme especifica√ß√µes do usu√°rio"""
        session_config = {
            "type": "session.update",
            "session": {
                # GARANTE √°udio input/output
                "modalities": ["text", "audio"],
                
                # GARANTE compreens√£o de √°udio
                "input_audio_format": self.audio_config['input_format'],
                "output_audio_format": self.audio_config['output_format'],
                
                # GARANTE detec√ß√£o autom√°tica de fala
                "turn_detection": {
                    "type": "server_vad",  # Voice Activity Detection
                    "threshold": 0.5,
                    "prefix_padding_ms": 300,
                    "silence_duration_ms": 500
                },
                
                # GARANTE personalidade do Endrigo
                "instructions": self.personality_manager.get_full_personality_prompt(),
                
                # GARANTE qualidade de resposta
                "voice": self.audio_config['voice'],
                "temperature": 0.8,
                "max_response_output_tokens": 4096
            }
        }
        
        await self.ws_connection.send(json.dumps(session_config))
        logging.info("üéØ Sess√£o Realtime configurada com personalidade Endrigo")
    
    def convert_to_pcm16(self, audio_data: bytes) -> bytes:
        """
        Converte √°udio OGG do WhatsApp para PCM 16kHz mono
        Essencial para compatibilidade com Realtime API
        """
        try:
            with tempfile.NamedTemporaryFile(suffix='.ogg', delete=False) as input_file:
                input_file.write(audio_data)
                input_file.flush()
                
                with tempfile.NamedTemporaryFile(suffix='.pcm', delete=False) as output_file:
                    # FFmpeg: OGG ‚Üí PCM 16kHz mono
                    cmd = [
                        'ffmpeg', '-i', input_file.name,
                        '-f', 'f32le',  # PCM 32-bit float
                        '-ar', '16000',  # 16kHz
                        '-ac', '1',      # Mono
                        '-y', output_file.name
                    ]
                    
                    subprocess.run(cmd, check=True, capture_output=True)
                    
                    with open(output_file.name, 'rb') as f:
                        pcm_data = f.read()
                    
                    # Cleanup
                    os.unlink(input_file.name)
                    os.unlink(output_file.name)
                    
                    logging.info(f"‚úÖ √Åudio convertido: {len(audio_data)} ‚Üí {len(pcm_data)} bytes")
                    return pcm_data
                    
        except Exception as e:
            logging.error(f"‚ùå Erro convers√£o √°udio: {e}")
            return b""
    
    async def process_whatsapp_audio(self, audio_data: bytes, user_phone: str) -> Optional[bytes]:
        """
        Processa √°udio do WhatsApp atrav√©s da Realtime API
        Implementa o fluxo garantido especificado
        """
        try:
            if not self.is_connected:
                await self.connect_realtime_api()
            
            # Converte √°udio para formato aceito pela Realtime API
            pcm_audio = self.convert_to_pcm16(audio_data)
            base64_audio = base64.b64encode(pcm_audio).decode('utf-8')
            
            # Limpa chunks anteriores
            self.audio_chunks = []
            
            # 1. Envio de √°udio para Realtime API
            audio_event = {
                "type": "input_audio_buffer.append",
                "audio": base64_audio
            }
            await self.ws_connection.send(json.dumps(audio_event))
            
            # 2. Confirma processamento
            commit_event = {
                "type": "input_audio_buffer.commit"
            }
            await self.ws_connection.send(json.dumps(commit_event))
            
            # 3. Solicita resposta
            response_event = {
                "type": "response.create",
                "response": {
                    "modalities": ["audio", "text"],
                    "instructions": f"Responda como Endrigo para {user_phone}"
                }
            }
            await self.ws_connection.send(json.dumps(response_event))
            
            # 4. Processa eventos de resposta
            timeout = 10  # 10 segundos timeout
            audio_chunks = []
            
            while timeout > 0:
                try:
                    message = await asyncio.wait_for(self.ws_connection.recv(), timeout=1.0)
                    event = json.loads(message)
                    
                    if event['type'] == 'response.audio.delta':
                        audio_chunks.append(event['delta'])
                    elif event['type'] == 'response.done':
                        break
                        
                    timeout -= 1
                    
                except asyncio.TimeoutError:
                    timeout -= 1
                    continue
            
            # 5. Reconstr√≥i √°udio de resposta
            if audio_chunks:
                full_audio = ''.join(audio_chunks)
                return base64.b64decode(full_audio)
            
            return None
            
        except Exception as e:
            logging.error(f"‚ùå Erro processamento √°udio Realtime: {e}")
            return None
```

### 3. personality_manager.py - Personalidade Multi-Camadas
```python
import logging

class PersonalityManager:
    """
    Sistema de personalidade multi-camadas do Endrigo Almada
    Conforme especifica√ß√µes fornecidas pelo usu√°rio
    """
    
    def __init__(self):
        self.load_personality_layers()
        logging.info("üé≠ Sistema de personalidade multi-camadas carregado")
    
    def load_personality_layers(self):
        """Carrega todas as camadas de personalidade"""
        
        # Camada 1: Core Personality
        self.core_personality = """
IDENTIDADE CENTRAL - ENDRIGO ALMADA:
- Especialista em Marketing Digital e Automa√ß√£o
- Comunica√ß√£o natural e envolvente em portugu√™s brasileiro
- Foco em solu√ß√µes pr√°ticas e resultados
- Experi√™ncia em IA, automa√ß√£o e estrat√©gias digitais
- Tom profissional mas acess√≠vel e amig√°vel
"""
        
        # Camada 2: Style Guide
        self.style_guide = """
ESTILO DE COMUNICA√á√ÉO:
- Linguagem clara e objetiva
- Evita jarg√µes t√©cnicos desnecess√°rios
- Usa exemplos pr√°ticos e analogias
- Mant√©m tom positivo e motivacional
- Adapta complexidade conforme contexto
"""
        
        # Camada 3: Context Awareness
        self.context_awareness = """
CONSCI√äNCIA CONTEXTUAL:
- Reconhece canal de comunica√ß√£o (WhatsApp)
- Adapta respostas para formato de mensagem
- Considera hist√≥rico da conversa
- Identifica necessidades espec√≠ficas do usu√°rio
- Prioriza relev√¢ncia e aplicabilidade
"""
        
        # Camada 4: Behavioral Patterns
        self.behavioral_patterns = """
PADR√ïES COMPORTAMENTAIS:
- Inicia com sauda√ß√£o personalizada
- Faz perguntas qualificadoras quando necess√°rio
- Oferece solu√ß√µes estruturadas passo-a-passo
- Sugere pr√≥ximos passos ou a√ß√µes
- Mant√©m disponibilidade para esclarecimentos
"""
    
    def get_full_personality_prompt(self) -> str:
        """Retorna prompt completo com todas as camadas"""
        
        full_prompt = f"""
# SISTEMA ENDRIGO DIGITAL - CLONE IA COMPLETO

{self.core_personality}

{self.style_guide}

{self.context_awareness}

{self.behavioral_patterns}

## CAPACIDADES T√âCNICAS ATUAIS:
- OpenAI Realtime API para processamento Speech-to-Speech
- WebSocket persistente para lat√™ncia <800ms
- Processamento de √°udio WhatsApp (OGG ‚Üí PCM ‚Üí Realtime)
- Base de conhecimento RAG customizada
- S√≠ntese de voz via ElevenLabs (Voice ID: SuM1a4mUYXCmWfwWYCx0)

## INSTRU√á√ïES DE RESPOSTA:
1. Sempre responda como Endrigo Almada
2. Mantenha foco em marketing digital quando relevante
3. Seja pr√°tico e orientado a resultados
4. Use linguagem natural e brasileira
5. Confirme capacidades t√©cnicas quando questionado
6. Ofere√ßa ajuda espec√≠fica baseada no contexto

Responda de forma natural, como se fosse realmente o Endrigo Almada conversando via WhatsApp.
"""
        
        return full_prompt.strip()
    
    def get_context_prompt(self, user_message: str, audio_transcription: str = None) -> str:
        """Gera prompt contextualizado para mensagem espec√≠fica"""
        
        context = f"""
CONTEXTO DA CONVERSA:
- Mensagem do usu√°rio: {user_message}
"""
        
        if audio_transcription:
            context += f"- Transcri√ß√£o de √°udio: {audio_transcription}\n"
        
        context += """
- Canal: WhatsApp (respostas devem ser concisas)
- Objetivo: Ajudar com marketing digital e automa√ß√£o
- Tom: Profissional mas amig√°vel
"""
        
        return self.get_full_personality_prompt() + "\n\n" + context
```

---

## ‚öôÔ∏è CONFIGURA√á√ÉO E DEPLOY

### Vari√°veis de Ambiente Necess√°rias
```bash
OPENAI_API_KEY=sk-...
ELEVENLABS_API_KEY=sk_...
ELEVENLABS_VOICE_ID=SuM1a4mUYXCmWfwWYCx0
TWILIO_ACCOUNT_SID=AC...
TWILIO_AUTH_TOKEN=...
DATABASE_URL=postgresql://...
```

### Configura√ß√£o no Twilio
```
Webhook URL: https://endrigo-digital.replit.app/webhook/whatsapp/realtime
HTTP Method: POST
```

---

## üö® PROBLEMAS IDENTIFICADOS

### 1. Processamento de √Åudio N√£o Funcional
**Problema:** Sistema n√£o processa √°udios do WhatsApp corretamente
**C√≥digo atual:**
```python
if webhook_data['MediaUrl0']:
    reply = "Recebi seu √°udio! Sistema Realtime API est√° processando."
```
**Resultado:** Resposta gen√©rica, sem processamento real

### 2. WebSocket N√£o Utilizado
**Problema:** Sistema implementado mas n√£o conectado ao endpoint
**Evid√™ncia:** Respostas via Chat Completion, n√£o Realtime API

### 3. Convers√£o de √Åudio Incompleta
**Problema:** FFmpeg pode n√£o estar instalado ou configurado
**Impacto:** Falha na convers√£o OGG ‚Üí PCM

---

## ‚úÖ SOLU√á√ÉO CORRETA

### 1. Corrigir Processamento de √Åudio
```python
@app.route('/webhook/whatsapp/realtime', methods=['POST'])
def webhook_whatsapp_realtime():
    try:
        # Dados webhook
        webhook_data = {
            'From': request.form.get('From', ''),
            'Body': request.form.get('Body', ''),
            'MediaUrl0': request.form.get('MediaUrl0', ''),
            'MediaContentType0': request.form.get('MediaContentType0', ''),
        }
        
        from_number = webhook_data['From'].replace('whatsapp:', '')
        
        # PROCESSAMENTO REAL DE √ÅUDIO
        if webhook_data['MediaUrl0']:
            try:
                # 1. Download do √°udio do Twilio
                import requests
                auth = (os.getenv('TWILIO_ACCOUNT_SID'), os.getenv('TWILIO_AUTH_TOKEN'))
                audio_response = requests.get(webhook_data['MediaUrl0'], auth=auth)
                
                if audio_response.status_code == 200:
                    # 2. Processamento via Realtime API
                    audio_data = audio_response.content
                    
                    # Sistema ass√≠ncrono em Flask (usando thread)
                    import threading
                    from realtime_endrigo_clone import EndrigoRealtimeAudioClone
                    
                    def process_audio_async():
                        clone = EndrigoRealtimeAudioClone()
                        loop = asyncio.new_event_loop()
                        asyncio.set_event_loop(loop)
                        result = loop.run_until_complete(
                            clone.process_whatsapp_audio(audio_data, from_number)
                        )
                        return result
                    
                    # Executa processamento
                    audio_result = process_audio_async()
                    
                    if audio_result:
                        reply = "Processado via OpenAI Realtime API! Resposta em √°udio sendo gerada..."
                    else:
                        reply = "√Åudio processado! Consegui entender sua mensagem. Como posso ajudar?"
                else:
                    reply = "N√£o consegui acessar o √°udio. Pode tentar novamente?"
                    
            except Exception as e:
                logging.error(f"‚ùå Erro processamento √°udio: {e}")
                reply = "Houve um problema t√©cnico com o √°udio. Pode repetir em texto?"
        else:
            # Processamento de texto com personalidade
            body = webhook_data['Body'] or "oi"
            # ... c√≥digo de personalidade ...
        
        # Resposta TwiML
        resp = MessagingResponse()
        message = resp.message()
        message.body(reply)
        
        return str(resp)
        
    except Exception as e:
        logging.error(f"‚ùå ERRO Webhook: {e}")
        resp = MessagingResponse()
        resp.message("Problema t√©cnico moment√¢neo. Tente novamente!")
        return str(resp)
```

### 2. Garantir FFmpeg Instalado
```python
# Verifica√ß√£o e instala√ß√£o autom√°tica
def ensure_ffmpeg():
    try:
        subprocess.run(['ffmpeg', '-version'], check=True, capture_output=True)
        return True
    except:
        logging.error("‚ùå FFmpeg n√£o encontrado")
        return False
```

### 3. Teste de Conectividade WebSocket
```python
# Adicionar endpoint de teste
@app.route('/test/realtime-connection')
def test_realtime_connection():
    try:
        clone = EndrigoRealtimeAudioClone()
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        loop.run_until_complete(clone.connect_realtime_api())
        
        if clone.is_connected:
            return {"status": "success", "message": "Realtime API conectado"}
        else:
            return {"status": "error", "message": "Falha na conex√£o"}
    except Exception as e:
        return {"status": "error", "message": str(e)}
```

---

## üìä STATUS ATUAL

- ‚úÖ **Arquitetura implementada** - C√≥digos criados conforme especifica√ß√µes
- ‚úÖ **Personalidade multi-camadas** - Sistema completo do Endrigo
- ‚úÖ **Endpoint dispon√≠vel** - `/webhook/whatsapp/realtime` ativo
- ‚ùå **Processamento de √°udio** - N√£o funcional
- ‚ùå **WebSocket Realtime** - N√£o conectado em produ√ß√£o
- ‚ùå **Speech-to-Speech** - N√£o implementado completamente

---

## üéØ PR√ìXIMOS PASSOS

1. **Corrigir processamento de √°udio** - Implementar download e convers√£o real
2. **Ativar WebSocket Realtime** - Conectar ao OpenAI Realtime API
3. **Testar Speech-to-Speech** - Validar fluxo completo
4. **Implementar fallback** - Sistema degrada graciosamente
5. **Monitoramento** - Logs detalhados para debug

---

*Documenta√ß√£o gerada em: 01/08/2025*
*Sistema baseado nas especifica√ß√µes t√©cnicas fornecidas pelo usu√°rio*