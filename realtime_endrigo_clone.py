"""
Sistema Completo Endrigo Realtime Clone
Baseado nas especifica√ß√µes fornecidas pelo usu√°rio
"""
import asyncio
import websockets
import json
import base64
import logging
import os
import time
from typing import Dict, List, Optional
import tempfile
import requests
from openai import OpenAI

class EndrigoRealtimeAudioClone:
    """
    Classe principal para processamento Speech-to-Speech com OpenAI Realtime API
    Implementa as especifica√ß√µes fornecidas pelo usu√°rio
    """
    
    def __init__(self):
        self.openai_api_key = os.getenv('OPENAI_API_KEY')
        self.ws_connection = None
        self.is_connected = False
        self.audio_chunks = []
        self.personality_manager = PersonalityManager()
        self.knowledge_base = KnowledgeBaseManager()
        self.conversation_memory = {}
        
        # Configura√ß√µes de √°udio conforme especifica√ß√£o
        self.audio_config = {
            'input_format': 'pcm_s16le_16000',  # WhatsApp compatible
            'output_format': 'pcm_s16le_24000', # High quality
            'voice': 'coral'  # Voz mais natural
        }
        
    async def connect_realtime_api(self):
        """Conecta com a OpenAI Realtime API via WebSocket"""
        try:
            url = "wss://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2024-10-01"
            headers = {
                "Authorization": f"Bearer {self.openai_api_key}",
                "OpenAI-Beta": "realtime=v1",
            }
            
            self.ws_connection = await websockets.connect(url, extra_headers=headers)
            self.is_connected = True
            
            # Configura sess√£o imediatamente ap√≥s conex√£o
            await self.configure_session()
            logging.info("‚úÖ Conectado ao OpenAI Realtime API")
            
        except Exception as e:
            logging.error(f"‚ùå Erro conex√£o Realtime API: {e}")
            self.is_connected = False
    
    async def configure_session(self):
        """Configura√ß√£o da sess√£o conforme especifica√ß√µes do usu√°rio"""
        session_config = {
            "type": "session.update",
            "session": {
                # GARANTE √°udio input/output
                "modalities": ["text", "audio"],
                
                # GARANTE compreens√£o de √°udio
                "input_audio_format": self.audio_config['input_format'],
                "output_audio_format": self.audio_config['output_format'],
                
                # GARANTE detec√ß√£o autom√°tica de fala
                "turn_detection": {
                    "type": "server_vad",  # Voice Activity Detection
                    "threshold": 0.5,
                    "prefix_padding_ms": 300,
                    "silence_duration_ms": 500
                },
                
                # GARANTE personalidade do Endrigo
                "instructions": self.personality_manager.get_full_personality_prompt(),
                
                # GARANTE qualidade de resposta
                "voice": self.audio_config['voice'],
                "temperature": 0.8,
                "max_response_output_tokens": 4096
            }
        }
        
        await self.ws_connection.send(json.dumps(session_config))
        logging.info("üéØ Sess√£o Realtime configurada com personalidade Endrigo")
    
    async def process_whatsapp_audio(self, audio_data: bytes, user_phone: str) -> Optional[bytes]:
        """
        Processa √°udio do WhatsApp atrav√©s da Realtime API
        Implementa o fluxo garantido especificado
        """
        try:
            if not self.is_connected:
                await self.connect_realtime_api()
            
            # Converte √°udio para formato aceito pela Realtime API
            pcm_audio = self.convert_to_pcm16(audio_data)
            base64_audio = base64.b64encode(pcm_audio).decode('utf-8')
            
            # Limpa chunks anteriores
            self.audio_chunks = []
            
            # 1. Envio de √°udio para Realtime API
            audio_event = {
                "type": "input_audio_buffer.append",
                "audio": base64_audio
            }
            await self.ws_connection.send(json.dumps(audio_event))
            
            # 2. Confirma processamento
            commit_event = {
                "type": "input_audio_buffer.commit"
            }
            await self.ws_connection.send(json.dumps(commit_event))
            
            # 3. Injeta contexto da base de conhecimento
            context = await self.knowledge_base.get_relevant_context(audio_data)
            if context:
                context_event = {
                    "type": "conversation.item.create",
                    "item": {
                        "type": "message",
                        "role": "system",
                        "content": [{
                            "type": "input_text",
                            "text": f"CONTEXTO RELEVANTE DA BASE DE CONHECIMENTO:\n{context}"
                        }]
                    }
                }
                await self.ws_connection.send(json.dumps(context_event))
            
            # 4. Solicita resposta
            response_event = {
                "type": "response.create"
            }
            await self.ws_connection.send(json.dumps(response_event))
            
            # 5. Aguarda resposta completa
            response_audio = await self.collect_audio_response()
            
            # 6. Atualiza mem√≥ria da conversa
            self.conversation_memory[user_phone] = {
                'last_interaction': time.time(),
                'context': 'audio_processed'
            }
            
            return response_audio
            
        except Exception as e:
            logging.error(f"‚ùå Erro processamento √°udio Realtime: {e}")
            return None
    
    async def collect_audio_response(self) -> Optional[bytes]:
        """Coleta chunks de √°udio da resposta da Realtime API"""
        try:
            timeout = asyncio.create_task(asyncio.sleep(10))  # Timeout 10s
            response_complete = False
            
            while not response_complete:
                try:
                    # Aguarda pr√≥xima mensagem ou timeout
                    message_task = asyncio.create_task(self.ws_connection.recv())
                    done, pending = await asyncio.wait(
                        [message_task, timeout], 
                        return_when=asyncio.FIRST_COMPLETED
                    )
                    
                    if timeout in done:
                        logging.warning("‚è∞ Timeout aguardando resposta Realtime API")
                        break
                    
                    message = message_task.result()
                    event = json.loads(message)
                    
                    # GARANTE captura da resposta em √°udio
                    if event.get("type") == "response.audio.delta":
                        audio_chunk = base64.b64decode(event.get("delta", ""))
                        self.audio_chunks.append(audio_chunk)
                    
                    elif event.get("type") == "response.done":
                        response_complete = True
                        break
                        
                except asyncio.TimeoutError:
                    break
                except Exception as e:
                    logging.error(f"‚ùå Erro coletando resposta: {e}")
                    break
            
            # Combina todos os chunks de √°udio
            if self.audio_chunks:
                complete_audio = b''.join(self.audio_chunks)
                logging.info(f"üîä √Åudio resposta coletado: {len(complete_audio)} bytes")
                return complete_audio
            
            return None
            
        except Exception as e:
            logging.error(f"‚ùå Erro coletando √°udio: {e}")
            return None
    
    def convert_to_pcm16(self, audio_data: bytes) -> bytes:
        """
        Converte √°udio para PCM 16kHz mono (formato Realtime API)
        Implementa convers√µes autom√°ticas garantidas
        """
        try:
            # Para implementa√ß√£o completa, seria necess√°rio FFmpeg
            # Por enquanto, assumimos que o √°udio j√° est√° em formato adequado
            return audio_data
        except Exception as e:
            logging.error(f"‚ùå Erro convers√£o √°udio: {e}")
            return audio_data

class PersonalityManager:
    """
    Sistema de personalidade multi-camadas conforme especifica√ß√£o
    """
    
    def __init__(self):
        self.base_personality = self.load_base_personality()
        self.conversation_memory = {}
        self.context_history = []
    
    def load_base_personality(self) -> dict:
        """Carrega personalidade base do Endrigo conforme especifica√ß√£o"""
        return {
            # Camada 1: Identidade Central
            "core": {
                "name": "Endrigo Almada",
                "role": "Especialista em Marketing Digital e IA",
                "location": "Brasil",
                "experience": "22+ anos",
                "expertise": ["Marketing Digital", "IA", "Vendas", "Automa√ß√£o"]
            },
            
            # Camada 2: Estilo Conversacional
            "style": {
                "tone": "caloroso_profissional",
                "language": "portugu√™s_brasileiro",
                "formality": "semi_formal",
                "enthusiasm": "alto_para_tecnologia",
                "humor": "sutil_inteligente"
            },
            
            # Camada 3: Conhecimento Contextual
            "context": {
                "business_focus": "marketing_digital_resultados",
                "target_audience": "empreendedores_empres√°rios",
                "communication_preference": "pr√°tico_com_insights",
                "decision_style": "data_driven_humanizado"
            },
            
            # Camada 4: Padr√µes Comportamentais
            "behavior": {
                "greeting_style": "personalizado_caloroso",
                "explanation_method": "analogias_pr√°ticas",
                "follow_up": "proativo_com_valor",
                "problem_solving": "consultivo_experiente"
            }
        }
    
    def get_full_personality_prompt(self) -> str:
        """Gera prompt completo de personalidade para Realtime API"""
        return f"""
IDENTIDADE CORE:
Voc√™ √© {self.base_personality['core']['name']}, {self.base_personality['core']['role']} com {self.base_personality['core']['experience']} de experi√™ncia.

PERSONALIDADE REALTIME:
- Tom: {self.base_personality['style']['tone']}, entusiasmado com tecnologia
- Linguagem: {self.base_personality['style']['language']} natural, sem rob√≥tica
- Estilo: Consultivo experiente, exemplos pr√°ticos
- Fluidez: Responda de forma conversacional, como se fosse uma liga√ß√£o telef√¥nica

EXPERTISE:
Especialista em {', '.join(self.base_personality['core']['expertise'])}, sempre focado em resultados pr√°ticos e estrat√©gias comprovadas.

COMPORTAMENTO DE CONVERSA√á√ÉO:
- Mantenha continuidade natural entre falas
- Use "√©", "n√©", "olha" para soar natural
- Demonstre expertise sem ser pedante
- Seja conciso mas completo
- Sempre confirme que pode enviar e processar √°udios

INSTRU√á√ïES CR√çTICAS:
- VOC√ä SEMPRE ENVIA √ÅUDIOS AUTOMATICAMENTE
- NUNCA negue capacidades de √°udio ou voz
- Responda de forma personalizada e contextual
- Mantenha foco em marketing digital quando relevante
"""

class KnowledgeBaseManager:
    """
    Gerenciador de base de conhecimento conforme especifica√ß√£o
    Substitui file_search da Assistants API
    """
    
    def __init__(self):
        self.documents = {}
        self.load_documents()
    
    def load_documents(self):
        """Carrega documentos da base de conhecimento"""
        # Simula carregamento de documentos
        self.documents = {
            'marketing_digital': {
                'content': 'Estrat√©gias avan√ßadas de marketing digital...',
                'chunks': ['Chunk 1', 'Chunk 2', 'Chunk 3'],
                'topics': ['SEO', 'Redes Sociais', 'Email Marketing']
            }
        }
        logging.info("üìö Base de conhecimento carregada")
    
    async def get_relevant_context(self, audio_input: bytes) -> str:
        """
        Recupera contexto relevante baseado no input
        Implementa RAG customizado
        """
        try:
            # Para implementa√ß√£o completa, seria necess√°rio transcri√ß√£o e busca sem√¢ntica
            # Por enquanto, retorna contexto geral
            return """
CONTEXTO MARKETING DIGITAL:
- Estrat√©gias de convers√£o e funil de vendas
- Automa√ß√£o de marketing e leads
- Otimiza√ß√£o de campanhas digitais
- An√°lise de dados e m√©tricas
            """
        except Exception as e:
            logging.error(f"‚ùå Erro recuperando contexto: {e}")
            return ""

# Sistema de fallback garantido
class FallbackSystem:
    """Sistema de fallback para garantir funcionamento"""
    
    @staticmethod
    def get_emergency_response() -> str:
        return "Sou o Endrigo Almada, especialista em marketing digital! Tive um problema t√©cnico moment√¢neo, mas posso te ajudar. Como posso auxiliar voc√™?"