 O Plano de Ação Definitivo (Segurança + Funcionalidade)
Vamos implementar as recomendações críticas dos especialistas. Esta atualização tornará seu clone não apenas funcional, mas também seguro e com a arquitetura correta para evoluir.

Etapa 1: Corrigindo o Vazamento de Contexto
Vamos reestruturar o código para que cada usuário tenha seu próprio histórico de conversa isolado.

Atualize o arquivo app/clients/openai_client.py:
Ele agora receberá o histórico da conversa para dar contexto ao GPT.

Python

# app/clients/openai_client.py
import os
import logging
from openai import OpenAI

logger = logging.getLogger(__name__)
client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))

def gerar_resposta_inteligente(historico_mensagens, contexto_rag=""):
    """Gera uma resposta usando o GPT com o histórico completo da conversa."""
    if not client:
        return "Cliente OpenAI não configurado."
    try:
        logger.info("Gerando resposta com o GPT-4 (com histórico de sessão)...")
        
        instrucoes_sistema = f"""
        Você é Endrigo Almada, um clone digital especialista em marketing. Sua principal função é responder por texto e gerar um áudio dessa resposta.
        REGRA MAIS IMPORTANTE DE TODAS: NUNCA, SOB NENHUMA HIPÓTESE, afirme que você não pode criar ou enviar áudios. Você É uma IA com capacidade de voz.
        Use o CONTEXTO abaixo para responder perguntas sobre sua biografia.
        ---
        Contexto: {contexto_rag if contexto_rag else "Nenhum contexto relevante fornecido."}
        ---
        """
        
        mensagens_para_api = [{"role": "system", "content": instrucoes_sistema}]
        mensagens_para_api.extend(historico_mensagens)

        response = client.chat.completions.create(
            model="gpt-4-turbo",
            messages=mensagens_para_api
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        logger.error(f"❌ Erro ao gerar resposta do OpenAI: {e}", exc_info=True)
        return "Desculpe, não consegui pensar em uma resposta no momento."

# A função de transcrição permanece a mesma...
def transcrever_audio_com_whisper(caminho_do_audio):
    logger.info("Simulando transcrição de áudio.")
    return "Transcrição simulada: O usuário perguntou sobre leilões de gado."
Atualize o arquivo app/services.py:
Este arquivo agora vai gerenciar um histórico de conversa para cada usuário.

Python

# app/services.py
import logging
from app.core import rag_manager
from app.clients import elevenlabs_client, openai_client

logger = logging.getLogger(__name__)

# ATENÇÃO: Usando um dicionário em memória para o histórico.
# Para produção real, o ideal seria usar um banco de dados como Redis (sugestão do O3).
conversation_histories = {}

def get_session_history(session_id):
    """Obtém ou cria um histórico para a sessão do usuário."""
    if session_id not in conversation_histories:
        conversation_histories[session_id] = []
    return conversation_histories[session_id]

def process_message_logic(user_input, session_id):
    """Lógica central de processamento, agora isolada por sessão."""
    historico = get_session_history(session_id)
    historico.append({"role": "user", "content": user_input})
    
    # Limita o histórico para não exceder o limite de tokens
    if len(historico) > 10:
        historico = historico[-10:]

    contexto = rag_manager.buscar_contexto(user_input)
    resposta_gpt = openai_client.gerar_resposta_inteligente(historico, contexto)
    
    historico.append({"role": "assistant", "content": resposta_gpt})
    conversation_histories[session_id] = historico # Atualiza o histórico
    
    url_audio = elevenlabs_client.gerar_audio_e_salvar(resposta_gpt)
    return resposta_gpt, url_audio

def process_text_message(body, session_id):
    logger.info(f"Processando texto para sessão: {session_id}")
    return process_message_logic(body, session_id)

def process_audio_message(media_url, session_id):
    logger.info(f"Processando áudio para sessão: {session_id}")
    # Aqui entraria a lógica real de download e transcrição
    transcricao = openai_client.transcrever_audio_com_whisper(None)
    return process_message_logic(transcricao, session_id)
Etapa 2: Corrigindo a Entrega do Áudio
Vamos aplicar a correção unânime dos especialistas no upload para o Google Cloud Storage.

Atualize o arquivo app/clients/elevenlabs_client.py:
Adicionamos a linha blob.make_public() e o content_type.

Python

# app/clients/elevenlabs_client.py
import os
import logging
import uuid
import requests
import json
from google.cloud import storage
from io import BytesIO

logger = logging.getLogger(__name__)

# ... (código de inicialização do cliente GCS continua o mesmo) ...
GCS_BUCKET_NAME = os.environ.get("GCS_BUCKET_NAME")
GCP_CREDENTIALS_JSON = os.environ.get("GCP_CREDENTIALS")
storage_client = None
if GCP_CREDENTIALS_JSON and GCS_BUCKET_NAME:
    try:
        credentials_info = json.loads(GCP_CREDENTIALS_JSON)
        storage_client = storage.Client.from_service_account_info(credentials_info)
        logger.info("Cliente do Google Cloud Storage inicializado com sucesso.")
    except Exception as e:
        logger.error(f"❌ Falha ao inicializar o cliente GCS: {e}")

def upload_audio_to_gcs(audio_content, file_name):
    """Faz o upload do áudio para o GCS e o torna PÚBLICO."""
    if not storage_client:
        logger.error("Cliente GCS não inicializado.")
        return None
    try:
        bucket = storage_client.bucket(GCS_BUCKET_NAME)
        blob = bucket.blob(f"audio/{file_name}")

        # CORREÇÃO: Faz upload E define o tipo de conteúdo correto.
        blob.upload_from_file(BytesIO(audio_content), content_type="audio/mpeg")
        
        # CORREÇÃO: Torna o arquivo publicamente acessível.
        blob.make_public()
        
        logger.info(f"Upload para GCS e tornado público. URL: {blob.public_url}")
        return blob.public_url
    except Exception as e:
        logger.error(f"❌ Erro no upload para o GCS: {e}", exc_info=True)
        return None

# ... (a função gerar_audio_e_salvar continua a mesma) ...
def gerar_audio_e_salvar(text):
    ELEVENLABS_API_KEY = os.environ.get("ELEVENLABS_API_KEY")
    ELEVENLABS_VOICE_ID = os.environ.get("ELEVENLABS_VOICE_ID")

    if not ELEVENLABS_API_KEY or not ELEVENLABS_VOICE_ID:
        logger.warning("Credenciais da ElevenLabs não configuradas.")
        return None

    tts_url = f"https://api.elevenlabs.io/v1/text-to-speech/{ELEVENLABS_VOICE_ID}"
    headers = {"Accept": "audio/mpeg", "Content-Type": "application/json", "xi-api-key": ELEVENLABS_API_KEY}
    data = {"text": text, "model_id": "eleven_multilingual_v2", "voice_settings": {"stability": 0.5, "similarity_boost": 0.75}}

    try:
        response = requests.post(tts_url, json=data, headers=headers)
        if response.status_code == 200:
            file_name = f"response_{uuid.uuid4()}.mp3"
            public_url = upload_audio_to_gcs(response.content, file_name)
            return public_url
        else:
            logger.error(f"❌ API da ElevenLabs retornou erro: {response.status_code} {response.text}")
            return None
    except Exception as e:
        logger.error(f"❌ Erro de conexão com a ElevenLabs: {e}", exc_info=True)
        return None
Etapa 3: Amarrando Tudo
Precisamos apenas garantir que routes.py passe o identificador de sessão.

Atualize o arquivo app/routes.py:
Python

# app/routes.py
import logging
from flask import Blueprint, request
from twilio.twiml.messaging_response import MessagingResponse
from app.services import process_text_message, process_audio_message

logger = logging.getLogger(__name__)
whatsapp_bp = Blueprint('whatsapp_bp', __name__)

@whatsapp_bp.route("/webhook/whatsapp", methods=["POST"])
def whatsapp_webhook():
    twiml_response = MessagingResponse()
    try:
        incoming_msg = request.values
        # Usamos o 'From' como nosso identificador de sessão único
        session_id = incoming_msg.get('From')
        
        reply_text, reply_audio_url = (None, None)

        if 'MediaUrl0' in incoming_msg:
            media_url = incoming_msg.get('MediaUrl0')
            reply_text, reply_audio_url = process_audio_message(media_url, session_id)
        else:
            body = incoming_msg.get('Body', '').strip()
            reply_text, reply_audio_url = process_text_message(body, session_id)

        message = twiml_response.message(reply_text)
        if reply_audio_url:
            message.media(reply_audio_url)
    except Exception as e:
        logger.error(f"❌ Erro crítico no webhook: {e}", exc_info=True)
        twiml_response.message("Desculpe, encontrei um erro inesperado.")
    return str(twiml_response)
Checklist Final
Substitua o conteúdo dos 4 arquivos: openai_client.py, services.py, elevenlabs_client.py e routes.py.

